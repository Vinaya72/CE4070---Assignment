{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd46377",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c27fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "import random\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b78a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--lang=en\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9cb0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb54d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lockbit_data = pd.read_csv('lockbit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dafd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "companyNames = lockbit_data['Company'].tolist()\n",
    "testCompanyNames = [\"capgemini\", \"microsoft\", \"Salesforce\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b6e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_from_display_name(display_name):\n",
    "    parts = [part.strip() for part in display_name.split(',')]\n",
    "    country = parts[-1] if parts else np.nan\n",
    "    return country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b097ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_from_address(address):\n",
    "    geolocator = Nominatim(user_agent=\"http\")\n",
    "    location = geolocator.geocode(address)\n",
    "    country = get_country_from_display_name(location.address)\n",
    "    return country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a16a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_english_url(url):\n",
    "    if \"linkedin.com\" in url:\n",
    "        if \"?\" in url:\n",
    "            return url + \"&lang=en\"\n",
    "        else:\n",
    "            return url + \"?lang=en\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = []\n",
    "companyWebsite_list = []\n",
    "industry_list = []\n",
    "headquarter_list = []\n",
    "country_list = []\n",
    "description_list = []\n",
    "size_list = []\n",
    "specialities_list = []\n",
    "company_type_list = []\n",
    "linkedin_followers_list = []\n",
    "\n",
    "\n",
    "wait = WebDriverWait(driver, 5)\n",
    "number = 0\n",
    "for company in companyNames:\n",
    "    try:\n",
    "        driver.delete_all_cookies()\n",
    "        driver.get('https://www.google.com')\n",
    "        search = driver.find_element(By.NAME, 'q') \n",
    "        search.send_keys(company + ' linkedin')\n",
    "        search.send_keys(Keys.RETURN)\n",
    "        linkedin_page = driver.find_element(By.TAG_NAME,'h3') \n",
    "        time.sleep(2) \n",
    "        linkedin_page.click()\n",
    "    \n",
    "\n",
    "        if \"linkedin\" in driver.current_url:\n",
    "\n",
    "            loaded = wait.until(EC.presence_of_element_located((By.ID, \"main-content\")))\n",
    "\n",
    "\n",
    "            try:\n",
    "                website_element = driver.find_element(By.CSS_SELECTOR, 'div[data-test-id=\"about-us__website\"] a[data-tracking-control-name=\"about_website\"]')         \n",
    "                website_text = website_element.get_attribute('href')\n",
    "            except Exception as e:\n",
    "                website_text = np.nan\n",
    "                print(e)\n",
    "                \n",
    "            companyWebsite_list.append(website_text)\n",
    "            \n",
    "            try:\n",
    "                name_element = driver.find_element(By.CLASS_NAME, 'top-card-layout__title')\n",
    "                company_name = name_element.text.strip()\n",
    "                \n",
    "            except Exception as e:\n",
    "                company_name = np.nan\n",
    "                print(e)\n",
    "                \n",
    "                \n",
    "            names_list.append( company_name)\n",
    "\n",
    "            try:\n",
    "                industry_element = driver.find_element(By.CSS_SELECTOR, 'div[data-test-id=\"about-us__industry\"] dd')\n",
    "                industry_text = industry_element.text\n",
    "                \n",
    "            except Exception as e:\n",
    "                industry_text = np.nan\n",
    "                print(e)\n",
    "                \n",
    "            industry_list.append(industry_text)\n",
    "            \n",
    "            try:\n",
    "                size_element = driver.find_element(By.CSS_SELECTOR, 'div[data-test-id=\"about-us__size\"] dd')\n",
    "                size_text = size_element.text\n",
    "                \n",
    "            except Exception as e:\n",
    "                size_text = np.nan\n",
    "                print(e)\n",
    "                \n",
    "            size_list.append(size_text)\n",
    "            \n",
    "            try:\n",
    "                speciality_element = driver.find_element(By.CSS_SELECTOR, 'div[data-test-id=\"about-us__specialties\"] dd')\n",
    "                speciality_text = speciality_element.text\n",
    "                \n",
    "            except Exception as e:\n",
    "                speciality_text = np.nan\n",
    "                print(e)\n",
    "                \n",
    "            specialities_list.append(speciality_text)\n",
    "            \n",
    "            try:\n",
    "                company_type_element = driver.find_element(By.CSS_SELECTOR, 'div[data-test-id=\"about-us__organizationType\"] dd')\n",
    "                company_type_text = company_type_element.text\n",
    "                \n",
    "            except Exception as e:\n",
    "                company_type_text = np.nan\n",
    "                print(e)\n",
    "                \n",
    "            company_type_list.append(company_type_text)\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                description_element = driver.find_element(By.CSS_SELECTOR, 'p[data-test-id=\"about-us__description\"]')\n",
    "                description_text = description_element.text\n",
    "                \n",
    "            except Exception as e:\n",
    "                description_text = np.nan\n",
    "                print(e)\n",
    "                \n",
    "            description_list.append(description_text)\n",
    "            \n",
    "            try:\n",
    "                headquarters_element = driver.find_element(By.CSS_SELECTOR, 'div[data-test-id=\"about-us__headquarters\"] dd')\n",
    "                headquarters_text = headquarters_element.text\n",
    "                country = get_country_from_address(headquarters_text)\n",
    "                \n",
    "            except Exception as e:\n",
    "                headquarters_text = np.nan\n",
    "                country = np.nan\n",
    "                print(e)\n",
    "                \n",
    "            headquarter_list.append(headquarters_text)\n",
    "            country_list.append(country)\n",
    "            \n",
    "            try:\n",
    "                followers_element = driver.find_element(By.CLASS_NAME, 'top-card-layout__first-subline')\n",
    "                followers_text = followers_element.text.strip()            \n",
    "                match = re.search(r'(\\d[\\d,]*)\\s+followers', followers_text)\n",
    "                if match:\n",
    "                    followers = match.group(1) \n",
    "                else:\n",
    "                    print(\"No followers found\")\n",
    "               \n",
    "            except Exception as e:\n",
    "                followers = np.nan\n",
    "                print(e)\n",
    "                \n",
    "            linkedin_followers_list.append(followers)\n",
    "            print(names_list,\n",
    "                   companyWebsite_list,\n",
    "                   industry_list,\n",
    "                   headquarter_list,\n",
    "                   country_list,\n",
    "                   description_list,\n",
    "                   size_list,\n",
    "                   specialities_list,\n",
    "                   company_type_list,\n",
    "                   linkedin_followers_list)\n",
    "               \n",
    "\n",
    "        else:\n",
    "            names_list.append(np.nan)\n",
    "            description_list.append(np.nan)\n",
    "            companyWebsite_list.append(np.nan)\n",
    "            industry_list.append(np.nan)\n",
    "            headquarter_list.append(np.nan)\n",
    "            country_list.append(np.nan)\n",
    "            size_list.append(np.nan)\n",
    "            specialities_list.append(np.nan)\n",
    "            company_type_list.append(np.nan)\n",
    "            linkedin_followers_list.append(np.nan)\n",
    "\n",
    "    except Exception as e:\n",
    "        names_list.append(np.nan)\n",
    "        description_list.append(np.nan)\n",
    "        companyWebsite_list.append(np.nan)\n",
    "        industry_list.append(np.nan)\n",
    "        headquarter_list.append(np.nan)\n",
    "        country_list.append(np.nan)\n",
    "        size_list.append(np.nan)\n",
    "        specialities_list.append(np.nan)\n",
    "        company_type_list.append(np.nan)\n",
    "        linkedin_followers_list.append(np.nan)\n",
    "        print(e)\n",
    "    number += 1\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb26a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(country_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb3eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(industry_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c733d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    \"Company Name\": names_list,\n",
    "    \"Description\": description_list,\n",
    "    \"Headquarters\": headquarter_list,\n",
    "    \"Country\": country_list,\n",
    "    \"Website\": companyWebsite_list,\n",
    "    \"Industry\": industry_list,\n",
    "    \"Company Size\": size_list,\n",
    "    \"Specialities\": specialities_list,\n",
    "    \"Company Type\": company_type_list,\n",
    "    \"Followers\": linkedin_followers_list   \n",
    "}\n",
    "\n",
    "# Step 3: Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Replace all NaN values with None (which will translate to null in JSON or CSV)\n",
    "df = df.where(pd.notnull(df), None)\n",
    "\n",
    "# Step 4: Save to CSV\n",
    "df.to_csv('random_hub_linkedin_scraping.csv', index=False, na_rep='null')\n",
    "\n",
    "print(\"ransom_hub_linkedin_scraping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c6b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ZoomInfo\n",
    "revenue_list = []\n",
    "\n",
    "wait = WebDriverWait(driver, 5)\n",
    "for company in testCompanyNames:\n",
    "    try:\n",
    "        driver.get('https://www.google.com')\n",
    "        search = driver.find_element(By.NAME, 'q')\n",
    "        search.send_keys(company + ' revenue' + ' zoominfo')\n",
    "        search.send_keys(Keys.RETURN)\n",
    "        zoom_info_page = driver.find_element(By.TAG_NAME,'h3') # clicking the first search result\n",
    "        time.sleep(2) # to limit rate of requests to linkedin\n",
    "        zoom_info_page.click()\n",
    "    \n",
    "        if \"zoominfo\" in driver.current_url:\n",
    "            loaded = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"main\")))\n",
    "\n",
    "            \n",
    "            try:\n",
    "                revenue_elements = driver.find_elements(By.CSS_SELECTOR, 'span[_ngcontent-ng-c25350904].content')\n",
    "                print(len(revenue_elements))\n",
    "                revenue_element = revenue_elements[3]\n",
    "                revenue_text = revenue_element.text\n",
    "                print(revenue_text)\n",
    "                \n",
    "            except Exception as e:\n",
    "                revenue_text = np.nan\n",
    "                print(e)\n",
    "                \n",
    "            revenue_list.append(revenue_text)\n",
    "               \n",
    "\n",
    "        else:\n",
    "            renevue_list.append(np.nan)\n",
    "          \n",
    "\n",
    "    except Exception as e:\n",
    "        revenue_list.append(np.nan)\n",
    "        print(e)\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3e1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# List of companies to scrape\n",
    "companies = [\"Apple\", \"Google\", \"Microsoft\", \"Amazon\"]\n",
    "\n",
    "# Setup WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# Function to get revenue of a company\n",
    "def get_company_revenue(company_name):\n",
    "    search_url = f\"https://finance.yahoo.com/\"\n",
    "    driver.get(search_url)\n",
    "    \n",
    "    # Locate the search bar and search for the company\n",
    "    search_input = driver.find_element(By.ID, \"yfin-usr-qry\")\n",
    "    search_input.send_keys(company_name)\n",
    "    search_input.send_keys(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(3)  # Wait for the search results to load\n",
    "    \n",
    "    try:\n",
    "        # Find the link to the company's profile and click it\n",
    "        profile_link = driver.find_element(By.XPATH, \"//a[contains(text(), 'Statistics')]\")\n",
    "        profile_link.click()\n",
    "        \n",
    "        time.sleep(3)  # Wait for the profile page to load\n",
    "        \n",
    "        # Locate the revenue field and extract the text\n",
    "        revenue_element = driver.find_element(By.XPATH, \"//td[contains(text(), 'Total Revenue')]/following-sibling::td\")\n",
    "        revenue = revenue_element.text\n",
    "        print(f\"{company_name}: {revenue}\")\n",
    "        return revenue\n",
    "    except Exception as e:\n",
    "        print(f\"Could not get revenue for {company_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Scrape revenue for each company\n",
    "company_revenues = {}\n",
    "for company in companies:\n",
    "    revenue = get_company_revenue(company)\n",
    "    company_revenues[company] = revenue\n",
    "\n",
    "# Clean up\n",
    "driver.quit()\n",
    "\n",
    "# Print the collected data\n",
    "print(company_revenues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21b5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
